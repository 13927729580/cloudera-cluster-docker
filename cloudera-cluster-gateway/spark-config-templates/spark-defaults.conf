spark.authenticate=false
spark.dynamicAllocation.enabled=true
spark.dynamicAllocation.executorIdleTimeout=60
spark.dynamicAllocation.minExecutors=0
spark.dynamicAllocation.schedulerBacklogTimeout=1
spark.eventLog.enabled=true
spark.serializer=org.apache.spark.serializer.KryoSerializer
spark.shuffle.service.enabled=true
spark.shuffle.service.port=7337
spark.ui.killEnabled=true
spark.master=yarn
spark.submit.deployMode=client
#spark.sql.hive.metastore.jars=/usr/lib/hive/lib/*:/usr/lib/hadoop/client/*
#spark.sql.hive.metastore.version=1.1.0
#spark.sql.catalogImplementation=hive
spark.eventLog.dir={{ default .Env.SPARK_DEFAULTS_SPARK_EVENTLOG_DIR "hdfs://hdfs-namenode:8020/user/root/sparkApplicationHistory" }}
spark.yarn.historyServer.address={{ default .Env.SPARK_DEFAULTS_SPARK_YARN_HISTORYSERVER_ADDRESS "http://historyserver:19888" }}
spark.yarn.jars=local:/usr/lib/spark/assembly/lib/*
spark.driver.extraLibraryPath=/usr/lib/hadoop/lib/native
spark.executor.extraLibraryPath=/usr/lib/hadoop/lib/native
spark.yarn.am.extraLibraryPath=/usr/lib/hadoop/lib/native
spark.hadoop.mapreduce.application.classpath=
spark.hadoop.yarn.application.classpath=
spark.yarn.config.gatewayPath=
spark.yarn.config.replacementPath=
